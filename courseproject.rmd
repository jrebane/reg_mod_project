---
title: 'Analysis of MPG for Automatic and Manual Transmission Vehicles'
author: "Johannes Rebane"
date: "November 23, 2014"
output: 
        pdf_document:
                fig_caption: yes
fontsize: 10pt
---

# Executive Summary

In this report, we first explore the data provided in the `mtcars` set and find that, in general, manual transmission has a higher mean mpg than automatic transmission; however, we quickly note that there are other correlative attributes that could be more explanatory than transmission type than transmission type. 

By performing **three separate regression analyses** (a single variable regression, a regression with all variables included, and an optimized model derived using a stepwise algorithm), and by **measuring and comparing R-Squared Transmission P-Values** for each model, and by **quantifying and plotting model residual traits** we are able to conclude that **transmission type is not a statistically significant indicator of mpg**.

```{r message=FALSE, echo = FALSE}
library(datasets); data(mtcars);library(knitr)

mtcarsorig <- mtcars # Preserving Continuous Variables

mtcars$am <- factor(mtcars$am, levels = c(0, 1), 
                           labels = c("Automatic", "Manual"))
mtcars$cyl <- as.factor(mtcars$cyl)
mtcars$gear <- as.factor(mtcars$gear)
mtcars$vs     <- as.factor(mtcars$vs)

```

# Exploratory Data Analysis

Before we dive into model selection, we perform some basic exploratory data analysis. In this we want to get a visual sense of automatic vs. manual mpg performance and also get a high level view of the correlation coefficients of each of the variables to start hypothesizing what confounding variables may exist.

**Graphical Analysis**: As we can see in **Figure 1**, by comparing the distribution of mpg for automatic and manual transmission cars, manual transmission vehicles seem to generally be associated with a higher mpg value. However, there also seems to be quite a bit of overlap, and a great deal of variance for mpg values for each transmission mode.

**Basic Correlation Assessment**: By running a basic assessment of correlations of the different variables with `mpg`, we can see that there are a number of other variables that have a higher absolute correlation with `mpg`. As you can see in **figure 2**, only `qsec`, `gear`, and `carb` are less correlated with `mpg`. To generate this chart, we plot the absolute values generated from running the following code: `abs(cor(mtcarsorig$mpg,mtcarsorig[,-1]))`.

# Regression Analysis

## First Model: Regression using a single variable

For our first regression analysis, we set transmission type as the sole predictor of the outcome, mpg, and run a regression accordingly.

```{r}
single_fit <- lm(mpg ~ am, mtcars)
summary(single_fit)$coefficients
```

The coefficent, 7.2 suggests that, if we switch from automatic to manual transmission, we should expect an improvement (increase) of 7.2 miles per gallon. If we look at the **residual plots (Figure 3)** and see the distribution of residuals, we can see that the residual variation suggests that the model is a poor fit. Further supporting this, our `Adjusted R-Squared value` is ~`r round(summary(single_fit)$r.squared,3)`, implying that only ~36% of the changes in mpg are explained by this model. Therefore we will try different models to bring us closer to a good fit.

## Second Model: Regression using all variables

Next, we plot a regression using all variables to see if this provides a better fit.

```{r}
fit_all <- lm(mpg ~ am + cyl + gear + disp + hp + drat + wt, data = mtcars)
print(fit_all$coefficients)
```

The coefficent of ~1.35 suggests that, if we switch from automatic to manual transmission, we should expect an improvement (increase) of 1.35 mpg, much lower than our previous model. Now our `Adjusted R-Squared value` is ~`r round(summary(fit_all)$r.squared, 3)`, implying that ~86% of the changes in mpg are explained by this model. Let's try one more model to see if we can increase the R-Squared even further.

## Third Model: Regression using an optimized model

Here we leverage a stepwise algorithm to find a model that optimizes upon our previous model stored in `fit_all`.

```{r results='hide'}
step_model <- step(fit_all, trace = 0)
print(step_model)
```

We extract the ANOVA table to get a sense of how impactful the transmission factor is in this optimized model.

```{r xtable, results='asis', message=FALSE, echo =FALSE}
library(xtable)
print(xtable(summary(step_model)$coefficients), comment=F)
```

Based on this table, we can see that, while the coefficient indicates an increase in mpg of ~1.81 with manual transmission, the P-Value of `amManual` is much greater than some of the other factors in the table and, in fact, would not be statistically significant if we were assessing the importance with a 95% confidence interval. If we calculate our R-Squared as `cor(mtcars$mpg,predict(step_model))^2`, we see that the predictive accuracy of this model is higher than both previous models at `r cor(mtcars$mpg,predict(step_model))^2`.
 
Finally, the residual deviance of this model is higher than our previous model, and therefore has better fit. Therefore, we can conclude that transmission is not statistically significant as a predictor of mpg.

# Appendix I: Figures

The following pages include figures referenced in the report.

```{r graph, echo = F, message=FALSE, fig.cap = 'Absolute Value of correlations of vehicle attributes to mpg performance'}
require(dplyr)
library(ggplot2)
cor <- abs(cor(mtcarsorig$mpg,mtcarsorig[,-1]))
cortable <- data.frame(attr = dimnames(cor)[2], abs.corr = cor[1:10])
colnames(cortable) <- c("names", "abs.corr")

cortable <- cortable %>%
  mutate(mag = ifelse(abs.corr > cortable[cortable$names == "am",2], "greater", ifelse(abs.corr == cortable[cortable$names == "am",2], "equal", "less")))

xlab <- "Attribute"
ylab <- "Absolute Value of Correlation with MPG"
ggplot(data=cortable, aes(x=reorder(names,abs.corr), y=abs.corr, fill = mag)) + 
        geom_bar(stat="identity",) +
        scale_fill_manual(values = c("greater" = "#014d64", 
                                     "equal" = "black", "less" = "#adadad")) +
        theme(legend.position = "none") +
        xlab(xlab) + ylab(ylab)
```


```{r graph1, echo = F, message=FALSE, fig.cap = 'Distribution of MPG Performance by Transmission Type'}


xlab <- "Transmission Type"
ylab <- "Miles Per Gallon (MPG)"
g <- ggplot(data = mtcars, aes(x = factor(am), y = mpg, fill = am)) + 
        scale_fill_discrete(name = xlab) +
        xlab(xlab) + 
        ylab(ylab) +
        geom_violin(col = "black", size = 1.5)
print(g)
```


```{r graph2, echo=FALSE, message=FALSE, fig.cap = 'Residual Analysis of Single Variable Linear Regression', warning=FALSE}

autoplot.lm <- function(x, ..., which=c(1:3, 5), mfrow=c(1,1)){
        require(ggplot2)
        require(grid)
        df <- fortify(x)
        df <- cbind(df, rows=1:nrow(df))
        
        # residuals vs fitted
        g1 <- ggplot(df, aes(.fitted, .resid)) +
                geom_point()  +
                geom_smooth(se=FALSE) +
                geom_hline(linetype=2, size=.2) +
                scale_x_continuous("Fitted Values") +
                scale_y_continuous("Residual") +
                ggtitle("Residuals vs Fitted")
        
        # normal qq
        a <- quantile(df$.stdresid, c(0.25, 0.75))
        b <- qnorm(c(0.25, 0.75))
        slope <- diff(a)/diff(b)
        int <- a[1] - slope * b[1]
        g2 <- ggplot(df, aes(sample=.resid)) +
                stat_qq() +
                geom_abline(slope=slope, intercept=int) +
                scale_x_continuous("Theoretical Quantiles") +
                scale_y_continuous("Standardized Residuals") +
                ggtitle("Normal Q-Q")
        
        # scale-location
        g3 <- ggplot(df, aes(.fitted, sqrt(abs(.stdresid)))) +
                geom_point() +
                geom_smooth(se=FALSE) +
                scale_x_continuous("Fitted Values") +
                scale_y_continuous("Root of Standardized Residuals") +
                ggtitle("Scale-Location")
        
        # cook's distance
        g4 <-  ggplot(df, aes(rows, .cooksd, ymin=0, ymax=.cooksd)) +
                geom_point() + geom_linerange() +
                scale_x_continuous("Observation Number") +
                scale_y_continuous("Cook's distance") +
                ggtitle("Cook's Distance")
        
        # residuals vs leverage
        g5 <- ggplot(df, aes(.hat, .stdresid)) +
                geom_point() +
                geom_smooth(se=FALSE) +
                geom_hline(linetype=2, size=.2) +
                scale_x_continuous("Leverage") +
                scale_y_continuous("Standardized Residuals") +
                ggtitle("Residuals vs Leverage")
        
        # cooksd vs leverage
        g6 <- ggplot(df, aes(.hat, .cooksd)) +
                geom_point() +
                geom_smooth(se=FALSE) +
                scale_x_continuous("Leverage") +
                scale_y_continuous("Cook's distance") +
                ggtitle("Cook's dist vs Leverage")
        
        plots <- list(g1, g2, g3, g4, g5, g6)
        
        # making the plots
        grid.newpage()
        
        if (prod(mfrow)>1) {
                mypos <- expand.grid(1:mfrow[1], 1:mfrow[2])
                mypos <- mypos[with(mypos, order(Var1)), ]
                pushViewport(viewport(layout = grid.layout(mfrow[1], mfrow[2])))
                formatter <- function(.){}
        } else {
                mypos <- data.frame(matrix(1, length(which), 2))
                pushViewport(viewport(layout = grid.layout(1, 1)))
                formatter <- function(.) {
                        .dontcare <- readline("Hit <Return> to see next plot: ")
                        grid.newpage()
                }
        }
        
        j <- 1
        for (i in which){
                formatter()
                print(plots[[i]], vp=viewport(layout.pos.row=mypos[j,][1], layout.pos.col=mypos[j,][2]))
                j <- j+1
        }
}

autoplot(single_fit, which=c(1,2,4,5), mfrow=c(2,2))
```